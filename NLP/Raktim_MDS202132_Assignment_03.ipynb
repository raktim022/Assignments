{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LetQjJMUumZw",
        "outputId": "ca17a7c1-7e7c-4961-deee-64f9060ffcdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\",force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PONoimlRurqI",
        "outputId": "f08a794d-0d8e-4446-8a4c-f15a8f44682a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fasttext-langdetect\n",
            "  Downloading fasttext-langdetect-1.0.5.tar.gz (6.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fasttext>=0.9.1\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.9/dist-packages (from fasttext-langdetect) (2.27.1)\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.10.4-py3-none-any.whl (222 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from fasttext>=0.9.1->fasttext-langdetect) (67.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from fasttext>=0.9.1->fasttext-langdetect) (1.22.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.22.0->fasttext-langdetect) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.22.0->fasttext-langdetect) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.22.0->fasttext-langdetect) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.22.0->fasttext-langdetect) (3.4)\n",
            "Building wheels for collected packages: fasttext-langdetect, fasttext\n",
            "  Building wheel for fasttext-langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext-langdetect: filename=fasttext_langdetect-1.0.5-py3-none-any.whl size=7521 sha256=7f0e575237368f6977eb141fa69b4e2082bbb651108bf86ebedc5843552a085b\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/0b/90/a4681c284d9a0da966cb7b6c378836cd3b0c9f23dc9ec7dfc5\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp39-cp39-linux_x86_64.whl size=4395536 sha256=0c0d721a663d55b83558ca39f65d14d1ba07fb5bee437ff35520323001106970\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/57/bc/1741406019061d5664914b070bd3e71f6244648732bc96109e\n",
            "Successfully built fasttext-langdetect fasttext\n",
            "Installing collected packages: pybind11, fasttext, fasttext-langdetect\n",
            "Successfully installed fasttext-0.9.2 fasttext-langdetect-1.0.5 pybind11-2.10.4\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext-langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w1BQ2t9urtN",
        "outputId": "96dcbcd2-0218-4a43-c85a-9ddb194b4edb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from ftlangdetect import detect\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import spacy\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "import os \n",
        "from nltk import ngrams\n",
        "from collections import Counter\n",
        "import tqdm\n",
        "\n",
        "import nltk \n",
        "from nltk import ngrams\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dhQaIanurwI"
      },
      "outputs": [],
      "source": [
        "#Using zipfile to extract JSON files from the .zip file\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/pdf_json.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/files/\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKjxgW_wurzQ"
      },
      "outputs": [],
      "source": [
        "#Function to extract the text from the JSON files\n",
        "import json\n",
        "def extract_body_text(filename):\n",
        "  file1 = open(filename)\n",
        "  paper_content = json.load(file1)\n",
        "  abstract = \"\"\n",
        "  if \"abstract\" in paper_content :\n",
        "    for bt in paper_content [\"abstract\"]:\n",
        "      abstract = abstract + bt[\"text\"]\n",
        "  return ( abstract + '\\n').lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eLVCMAvur5_"
      },
      "outputs": [],
      "source": [
        "#Function for performing text preprocessing\n",
        "#Preprocessing includes case folding, removing punctuations and lemmatization\n",
        "def preprocessing(text):\n",
        "  res=\"\"\n",
        "\n",
        "  #Converting corpus to lower case\n",
        "  text=text.lower()\n",
        "\n",
        "  #Removing references\n",
        "  text=re.sub(\"\\[\\d+\\]\",\" \",text)\n",
        "\n",
        "  #Removing punctuations\n",
        "  text=re.sub(\"\"\"\\.|\\,|\\$|-|\\#|\\^|\\(|\\)|\\-|#|@|\\'|\\+|\\\"|\\/|\\;|\\:|\\%|\\=|\\*\"\"\",\" \",text)\n",
        "\n",
        "  #Removing multiple occurences of space with a single space\n",
        "  text=re.sub(\"\\s*\\s\",\" \",text)\n",
        "  \n",
        "  return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r063FnXVwAol",
        "outputId": "da4dae3c-f088-46d0-e5a0-38e0d276d612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "100%|██████████| 100/100 [00:01<00:00, 67.35it/s]\n"
          ]
        }
      ],
      "source": [
        "tokens=[]\n",
        "for j in tqdm.tqdm(os.listdir(\"files/pdf_json/\")[:100]):\n",
        "    try:\n",
        "      text=preprocessing(extract_body_text(f'files/pdf_json/{j}'))\n",
        "\n",
        "      #Detecting the language of the text\n",
        "      lang=detect(text,low_memory=False)\n",
        "\n",
        "      if lang[\"lang\"]==\"en\":\n",
        "\n",
        "        words=text.split(\" \")\n",
        "\n",
        "        words=[i for i in words if i!='']\n",
        "\n",
        "        tokens.extend(words)\n",
        "\n",
        "    except UnicodeDecodeError:\n",
        "      pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo3pjydN8wnX",
        "outputId": "b6a5a6d8-a492-4d3a-9b75-b0eedc208cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11738"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmp8liwIwAuZ"
      },
      "outputs": [],
      "source": [
        "#Creating sequences of words of length 25, i.e., for every sequence of 25 words, the 26th word is the output at that timestep\n",
        "word_sequences=[]\n",
        "\n",
        "train_len=25 + 1\n",
        "\n",
        "for i in range(train_len,len(tokens)):\n",
        "  w=tokens[i-train_len:i]\n",
        "  word_sequences.append(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>ENCODING THE SENTENCES</b>"
      ],
      "metadata": {
        "id": "5I_egyIwVTC9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mGDWHQA0YQJ"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obb6AW-K0daT"
      },
      "outputs": [],
      "source": [
        "#Using Tensorflow tokenizer object for encoding\n",
        "tokenizer=Tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mjvxYaI0fMJ"
      },
      "outputs": [],
      "source": [
        "#Fitting the object on the word sequences\n",
        "tokenizer.fit_on_texts(word_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vv18M0go0hMA"
      },
      "outputs": [],
      "source": [
        "sequences=tokenizer.texts_to_sequences(word_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AczI0H_p1Fva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad6e5d83-e997-448d-e8a4-448b4bbfc621"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 674,   13, 3347, ...,    2,  672,   44],\n",
              "       [  13, 3347,    5, ...,  672,   44,   25],\n",
              "       [3347,    5,    1, ...,   44,   25,  150],\n",
              "       ...,\n",
              "       [3336,   25, 3337, ...,    1,  495,    2],\n",
              "       [  25, 3337, 1556, ...,  495,    2, 3348],\n",
              "       [3337, 1556,    1, ...,    2, 3348, 3349]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#Making a matrix of the encoded word sequences\n",
        "sequences=np.array(sequences)\n",
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6iEJNbv0jI-"
      },
      "outputs": [],
      "source": [
        "vocab_size=len(tokenizer.word_counts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViAutDN_hxG2",
        "outputId": "aa147305-bb02-4c6d-854e-eae4cf11f350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3079"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlQx1lyW0pZE"
      },
      "outputs": [],
      "source": [
        "#importing the layers to build an RNN\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,LSTM,Dense\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Changed number of neurons to 150 to improve accuracy.</h4>"
      ],
      "metadata": {
        "id": "3hqs748Ju2Vl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLApAS9J0r96"
      },
      "outputs": [],
      "source": [
        "#creating the RNN with 2 LSTM layers\n",
        "\n",
        "def create_model(vocabulary_size, seq_len):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocabulary_size, 25, input_length=seq_len))\n",
        "    model.add(LSTM(150, return_sequences=True))\n",
        "    model.add(LSTM(150))\n",
        "    model.add(Dense(150, activation='relu'))\n",
        "\n",
        "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "   \n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdpnU4Gt0zey"
      },
      "outputs": [],
      "source": [
        "#Splitting the matrix into input sequences and labels\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "X=sequences[:,:-1]\n",
        "y=sequences[:,-1]\n",
        "y=to_categorical(y,num_classes=vocab_size+1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape,y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41W768LL6xAp",
        "outputId": "68693aad-e724-4401-bd4c-a8d3b5baff6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13075, 25), (13075, 3350))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHtlgyHD02D7"
      },
      "outputs": [],
      "source": [
        "seq_len=X.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c45HkOKO04Jl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "513d205a-30a7-44f6-a5d0-d55592f60bb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 25, 25)            77000     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 25, 150)           105600    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 150)               180600    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 150)               22650     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3080)              465080    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 850,930\n",
            "Trainable params: 850,930\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model=create_model(vocab_size+1,seq_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Changed the number of epochs from 150 to 200 to increase accuracy from 76% to 98%</h4>"
      ],
      "metadata": {
        "id": "Bc4pu8-guk83"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQ9orwsb05zM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c47ffbe6-a3f6-4ad5-d247-17ecbd5120a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "92/92 [==============================] - 33s 210ms/step - loss: 7.2734 - accuracy: 0.0399\n",
            "Epoch 2/200\n",
            "92/92 [==============================] - 9s 94ms/step - loss: 6.8722 - accuracy: 0.0450\n",
            "Epoch 3/200\n",
            "92/92 [==============================] - 7s 69ms/step - loss: 6.8171 - accuracy: 0.0465\n",
            "Epoch 4/200\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 6.6939 - accuracy: 0.0464\n",
            "Epoch 5/200\n",
            "92/92 [==============================] - 2s 26ms/step - loss: 6.6082 - accuracy: 0.0565\n",
            "Epoch 6/200\n",
            "92/92 [==============================] - 2s 25ms/step - loss: 6.5131 - accuracy: 0.0614\n",
            "Epoch 7/200\n",
            "92/92 [==============================] - 5s 50ms/step - loss: 6.4052 - accuracy: 0.0630\n",
            "Epoch 8/200\n",
            "92/92 [==============================] - 4s 41ms/step - loss: 6.2978 - accuracy: 0.0657\n",
            "Epoch 9/200\n",
            "92/92 [==============================] - 2s 19ms/step - loss: 6.1940 - accuracy: 0.0692\n",
            "Epoch 10/200\n",
            "92/92 [==============================] - 3s 28ms/step - loss: 6.0991 - accuracy: 0.0692\n",
            "Epoch 11/200\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 6.0146 - accuracy: 0.0716\n",
            "Epoch 12/200\n",
            "92/92 [==============================] - 3s 33ms/step - loss: 5.9410 - accuracy: 0.0721\n",
            "Epoch 13/200\n",
            "92/92 [==============================] - 3s 37ms/step - loss: 5.8634 - accuracy: 0.0727\n",
            "Epoch 14/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 5.7866 - accuracy: 0.0745\n",
            "Epoch 15/200\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 5.7127 - accuracy: 0.0764\n",
            "Epoch 16/200\n",
            "92/92 [==============================] - 1s 15ms/step - loss: 5.6241 - accuracy: 0.0785\n",
            "Epoch 17/200\n",
            "92/92 [==============================] - 1s 16ms/step - loss: 5.5393 - accuracy: 0.0826\n",
            "Epoch 18/200\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 5.4609 - accuracy: 0.0857\n",
            "Epoch 19/200\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 5.3769 - accuracy: 0.0917\n",
            "Epoch 20/200\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 5.3066 - accuracy: 0.0911\n",
            "Epoch 21/200\n",
            "92/92 [==============================] - 2s 19ms/step - loss: 5.2294 - accuracy: 0.0977\n",
            "Epoch 22/200\n",
            "92/92 [==============================] - 2s 19ms/step - loss: 5.1501 - accuracy: 0.0999\n",
            "Epoch 23/200\n",
            "92/92 [==============================] - 2s 22ms/step - loss: 5.0746 - accuracy: 0.1021\n",
            "Epoch 24/200\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 5.0034 - accuracy: 0.1051\n",
            "Epoch 25/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 4.9328 - accuracy: 0.1081\n",
            "Epoch 26/200\n",
            "92/92 [==============================] - 1s 16ms/step - loss: 4.8512 - accuracy: 0.1106\n",
            "Epoch 27/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 4.7795 - accuracy: 0.1141\n",
            "Epoch 28/200\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 4.7118 - accuracy: 0.1179\n",
            "Epoch 29/200\n",
            "92/92 [==============================] - 2s 25ms/step - loss: 4.6425 - accuracy: 0.1198\n",
            "Epoch 30/200\n",
            "92/92 [==============================] - 3s 29ms/step - loss: 4.5766 - accuracy: 0.1259\n",
            "Epoch 31/200\n",
            "92/92 [==============================] - 2s 26ms/step - loss: 4.5111 - accuracy: 0.1291\n",
            "Epoch 32/200\n",
            "92/92 [==============================] - 2s 23ms/step - loss: 4.4438 - accuracy: 0.1335\n",
            "Epoch 33/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 4.3725 - accuracy: 0.1337\n",
            "Epoch 34/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 4.3054 - accuracy: 0.1404\n",
            "Epoch 35/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 4.2520 - accuracy: 0.1428\n",
            "Epoch 36/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 4.1878 - accuracy: 0.1444\n",
            "Epoch 37/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 4.1280 - accuracy: 0.1508\n",
            "Epoch 38/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 4.1038 - accuracy: 0.1526\n",
            "Epoch 39/200\n",
            "92/92 [==============================] - 1s 10ms/step - loss: 4.0275 - accuracy: 0.1590\n",
            "Epoch 40/200\n",
            "92/92 [==============================] - 1s 15ms/step - loss: 3.9623 - accuracy: 0.1663\n",
            "Epoch 41/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 3.9023 - accuracy: 0.1705\n",
            "Epoch 42/200\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 3.8542 - accuracy: 0.1771\n",
            "Epoch 43/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 3.7932 - accuracy: 0.1817\n",
            "Epoch 44/200\n",
            "92/92 [==============================] - 1s 10ms/step - loss: 3.7399 - accuracy: 0.1866\n",
            "Epoch 45/200\n",
            "92/92 [==============================] - 1s 10ms/step - loss: 3.6991 - accuracy: 0.1902\n",
            "Epoch 46/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 3.6377 - accuracy: 0.2047\n",
            "Epoch 47/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 3.5832 - accuracy: 0.2064\n",
            "Epoch 48/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 3.5208 - accuracy: 0.2186\n",
            "Epoch 49/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 3.4707 - accuracy: 0.2253\n",
            "Epoch 50/200\n",
            "92/92 [==============================] - 1s 10ms/step - loss: 3.4209 - accuracy: 0.2323\n",
            "Epoch 51/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 3.3754 - accuracy: 0.2431\n",
            "Epoch 52/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 3.3351 - accuracy: 0.2448\n",
            "Epoch 53/200\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 3.2714 - accuracy: 0.2529\n",
            "Epoch 54/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 3.2328 - accuracy: 0.2579\n",
            "Epoch 55/200\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 3.1860 - accuracy: 0.2687\n",
            "Epoch 56/200\n",
            "92/92 [==============================] - 1s 15ms/step - loss: 3.1404 - accuracy: 0.2776\n",
            "Epoch 57/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 3.0946 - accuracy: 0.2843\n",
            "Epoch 58/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 3.0520 - accuracy: 0.2912\n",
            "Epoch 59/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 3.0080 - accuracy: 0.2994\n",
            "Epoch 60/200\n",
            "92/92 [==============================] - 1s 16ms/step - loss: 2.9708 - accuracy: 0.3046\n",
            "Epoch 61/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 2.9348 - accuracy: 0.3108\n",
            "Epoch 62/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 2.8964 - accuracy: 0.3166\n",
            "Epoch 63/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 2.8595 - accuracy: 0.3193\n",
            "Epoch 64/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 2.8181 - accuracy: 0.3373\n",
            "Epoch 65/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 2.7830 - accuracy: 0.3398\n",
            "Epoch 66/200\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 2.7464 - accuracy: 0.3416\n",
            "Epoch 67/200\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 2.7280 - accuracy: 0.3496\n",
            "Epoch 68/200\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 2.7807 - accuracy: 0.3505\n",
            "Epoch 69/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 2.6477 - accuracy: 0.3624\n",
            "Epoch 70/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 2.6082 - accuracy: 0.3762\n",
            "Epoch 71/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 2.5773 - accuracy: 0.3799\n",
            "Epoch 72/200\n",
            "92/92 [==============================] - 1s 15ms/step - loss: 2.5391 - accuracy: 0.3902\n",
            "Epoch 73/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 2.5146 - accuracy: 0.3922\n",
            "Epoch 74/200\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 2.9201 - accuracy: 0.3628\n",
            "Epoch 75/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 3.9697 - accuracy: 0.2599\n",
            "Epoch 76/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 2.8601 - accuracy: 0.3492\n",
            "Epoch 77/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 2.7199 - accuracy: 0.3654\n",
            "Epoch 78/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 3.1102 - accuracy: 0.3035\n",
            "Epoch 79/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 2.8867 - accuracy: 0.3361\n",
            "Epoch 80/200\n",
            "92/92 [==============================] - 2s 20ms/step - loss: 2.7426 - accuracy: 0.3577\n",
            "Epoch 81/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 2.6359 - accuracy: 0.3729\n",
            "Epoch 82/200\n",
            "92/92 [==============================] - 1s 10ms/step - loss: 2.5548 - accuracy: 0.3874\n",
            "Epoch 83/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 2.4904 - accuracy: 0.4009\n",
            "Epoch 84/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 2.4490 - accuracy: 0.4150\n",
            "Epoch 85/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 2.3738 - accuracy: 0.4277\n",
            "Epoch 86/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 2.3308 - accuracy: 0.4328\n",
            "Epoch 87/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 2.2701 - accuracy: 0.4453\n",
            "Epoch 88/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 2.2221 - accuracy: 0.4519\n",
            "Epoch 89/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 2.1812 - accuracy: 0.4610\n",
            "Epoch 90/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 2.4414 - accuracy: 0.4110\n",
            "Epoch 91/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 2.3802 - accuracy: 0.4225\n",
            "Epoch 92/200\n",
            "92/92 [==============================] - 1s 10ms/step - loss: 2.6965 - accuracy: 0.3440\n",
            "Epoch 93/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 2.3362 - accuracy: 0.4247\n",
            "Epoch 94/200\n",
            "92/92 [==============================] - 2s 26ms/step - loss: 2.2097 - accuracy: 0.4539\n",
            "Epoch 95/200\n",
            "92/92 [==============================] - 1s 16ms/step - loss: 2.1343 - accuracy: 0.4734\n",
            "Epoch 96/200\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 2.0701 - accuracy: 0.4868\n",
            "Epoch 97/200\n",
            "92/92 [==============================] - 1s 15ms/step - loss: 2.0109 - accuracy: 0.5044\n",
            "Epoch 98/200\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 1.9647 - accuracy: 0.5109\n",
            "Epoch 99/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 1.9147 - accuracy: 0.5225\n",
            "Epoch 100/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 1.8566 - accuracy: 0.5375\n",
            "Epoch 101/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 1.7984 - accuracy: 0.5511\n",
            "Epoch 102/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 1.7529 - accuracy: 0.5628\n",
            "Epoch 103/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 1.7911 - accuracy: 0.5476\n",
            "Epoch 104/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 1.7280 - accuracy: 0.5570\n",
            "Epoch 105/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 1.6659 - accuracy: 0.5760\n",
            "Epoch 106/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 1.6165 - accuracy: 0.5876\n",
            "Epoch 107/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 1.5657 - accuracy: 0.6005\n",
            "Epoch 108/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 1.5276 - accuracy: 0.6095\n",
            "Epoch 109/200\n",
            "92/92 [==============================] - 1s 15ms/step - loss: 1.4826 - accuracy: 0.6225\n",
            "Epoch 110/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 1.4385 - accuracy: 0.6301\n",
            "Epoch 111/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 1.4167 - accuracy: 0.6328\n",
            "Epoch 112/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 1.3940 - accuracy: 0.6430\n",
            "Epoch 113/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 1.4615 - accuracy: 0.6282\n",
            "Epoch 114/200\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 1.3995 - accuracy: 0.6393\n",
            "Epoch 115/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 1.3355 - accuracy: 0.6592\n",
            "Epoch 116/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 1.2844 - accuracy: 0.6674\n",
            "Epoch 117/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 1.2371 - accuracy: 0.6860\n",
            "Epoch 118/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 1.1980 - accuracy: 0.6930\n",
            "Epoch 119/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 1.1644 - accuracy: 0.6995\n",
            "Epoch 120/200\n",
            "92/92 [==============================] - 1s 13ms/step - loss: 1.1332 - accuracy: 0.7095\n",
            "Epoch 121/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 1.0889 - accuracy: 0.7195\n",
            "Epoch 122/200\n",
            "92/92 [==============================] - 1s 10ms/step - loss: 1.3317 - accuracy: 0.6644\n",
            "Epoch 123/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 1.3227 - accuracy: 0.6627\n",
            "Epoch 124/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 1.2203 - accuracy: 0.6919\n",
            "Epoch 125/200\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 1.1657 - accuracy: 0.7036\n",
            "Epoch 126/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 1.0915 - accuracy: 0.7205\n",
            "Epoch 127/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 1.0381 - accuracy: 0.7378\n",
            "Epoch 128/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.9976 - accuracy: 0.7505\n",
            "Epoch 129/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.9598 - accuracy: 0.7567\n",
            "Epoch 130/200\n",
            "92/92 [==============================] - 1s 10ms/step - loss: 0.9221 - accuracy: 0.7684\n",
            "Epoch 131/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.8815 - accuracy: 0.7787\n",
            "Epoch 132/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.8513 - accuracy: 0.7905\n",
            "Epoch 133/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.8194 - accuracy: 0.7987\n",
            "Epoch 134/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.7916 - accuracy: 0.8040\n",
            "Epoch 135/200\n",
            "92/92 [==============================] - 1s 10ms/step - loss: 0.7765 - accuracy: 0.8083\n",
            "Epoch 136/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.7652 - accuracy: 0.8110\n",
            "Epoch 137/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.7295 - accuracy: 0.8207\n",
            "Epoch 138/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.6902 - accuracy: 0.8342\n",
            "Epoch 139/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.6681 - accuracy: 0.8379\n",
            "Epoch 140/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.6427 - accuracy: 0.8455\n",
            "Epoch 141/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.6277 - accuracy: 0.8502\n",
            "Epoch 142/200\n",
            "92/92 [==============================] - 1s 10ms/step - loss: 0.6052 - accuracy: 0.8541\n",
            "Epoch 143/200\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.5810 - accuracy: 0.8632\n",
            "Epoch 144/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.5554 - accuracy: 0.8702\n",
            "Epoch 145/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.5385 - accuracy: 0.8749\n",
            "Epoch 146/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.5246 - accuracy: 0.8793\n",
            "Epoch 147/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.5060 - accuracy: 0.8831\n",
            "Epoch 148/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.4974 - accuracy: 0.8851\n",
            "Epoch 149/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.4803 - accuracy: 0.8908\n",
            "Epoch 150/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.4819 - accuracy: 0.8900\n",
            "Epoch 151/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.4657 - accuracy: 0.8935\n",
            "Epoch 152/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.4505 - accuracy: 0.8979\n",
            "Epoch 153/200\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.4355 - accuracy: 0.9012\n",
            "Epoch 154/200\n",
            "92/92 [==============================] - 1s 10ms/step - loss: 0.6349 - accuracy: 0.8533\n",
            "Epoch 155/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.7712 - accuracy: 0.8010\n",
            "Epoch 156/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.6607 - accuracy: 0.8284\n",
            "Epoch 157/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.5357 - accuracy: 0.8645\n",
            "Epoch 158/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.4879 - accuracy: 0.8822\n",
            "Epoch 159/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.4714 - accuracy: 0.8902\n",
            "Epoch 160/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.4843 - accuracy: 0.8853\n",
            "Epoch 161/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.4418 - accuracy: 0.8975\n",
            "Epoch 162/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.4192 - accuracy: 0.9027\n",
            "Epoch 163/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.3861 - accuracy: 0.9124\n",
            "Epoch 164/200\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.3649 - accuracy: 0.9168\n",
            "Epoch 165/200\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.3406 - accuracy: 0.9249\n",
            "Epoch 166/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.3200 - accuracy: 0.9320\n",
            "Epoch 167/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.3072 - accuracy: 0.9353\n",
            "Epoch 168/200\n",
            "92/92 [==============================] - 2s 21ms/step - loss: 0.3060 - accuracy: 0.9375\n",
            "Epoch 169/200\n",
            "92/92 [==============================] - 1s 16ms/step - loss: 0.2927 - accuracy: 0.9390\n",
            "Epoch 170/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.2887 - accuracy: 0.9390\n",
            "Epoch 171/200\n",
            "92/92 [==============================] - 1s 10ms/step - loss: 0.2942 - accuracy: 0.9372\n",
            "Epoch 172/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.2838 - accuracy: 0.9395\n",
            "Epoch 173/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.2720 - accuracy: 0.9449\n",
            "Epoch 174/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.2746 - accuracy: 0.9422\n",
            "Epoch 175/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.2701 - accuracy: 0.9423\n",
            "Epoch 176/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.2608 - accuracy: 0.9452\n",
            "Epoch 177/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.2489 - accuracy: 0.9485\n",
            "Epoch 178/200\n",
            "92/92 [==============================] - 1s 12ms/step - loss: 0.2405 - accuracy: 0.9509\n",
            "Epoch 179/200\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.2216 - accuracy: 0.9577\n",
            "Epoch 180/200\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.2348 - accuracy: 0.9518\n",
            "Epoch 181/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.3919 - accuracy: 0.9065\n",
            "Epoch 182/200\n",
            "92/92 [==============================] - 1s 10ms/step - loss: 0.5939 - accuracy: 0.8485\n",
            "Epoch 183/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.8191 - accuracy: 0.8023\n",
            "Epoch 184/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.5417 - accuracy: 0.8723\n",
            "Epoch 185/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.3508 - accuracy: 0.9267\n",
            "Epoch 186/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.2959 - accuracy: 0.9424\n",
            "Epoch 187/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.5501 - accuracy: 0.9002\n",
            "Epoch 188/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.8397 - accuracy: 0.8350\n",
            "Epoch 189/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.8021 - accuracy: 0.8168\n",
            "Epoch 190/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.5508 - accuracy: 0.8610\n",
            "Epoch 191/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.3671 - accuracy: 0.9081\n",
            "Epoch 192/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.2285 - accuracy: 0.9504\n",
            "Epoch 193/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.1733 - accuracy: 0.9696\n",
            "Epoch 194/200\n",
            "92/92 [==============================] - 1s 14ms/step - loss: 0.1626 - accuracy: 0.9723\n",
            "Epoch 195/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1333 - accuracy: 0.9788\n",
            "Epoch 196/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1173 - accuracy: 0.9857\n",
            "Epoch 197/200\n",
            "92/92 [==============================] - 1s 11ms/step - loss: 0.1235 - accuracy: 0.9834\n",
            "Epoch 198/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.1075 - accuracy: 0.9873\n",
            "Epoch 199/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.0992 - accuracy: 0.9886\n",
            "Epoch 200/200\n",
            "92/92 [==============================] - 1s 9ms/step - loss: 0.0924 - accuracy: 0.9879\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(X, y, batch_size=128, epochs=200,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history[\"loss\"],label=\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KZo8BF7I9inK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "03da5429-429b-416d-bca8-ea6319920778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"accuracy\"],label=\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "dcz3-2HtKPY5",
        "outputId": "a5164341-48e6-4fe8-e369-4ef4ba26a997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAv6ElEQVR4nO3deXxU1d3H8c/JvpJ9AZKQBQKEAIphERX0ERVXpLSK4oL1Ea211q3Wp7ZW6b6prbWtqFRrFVCsgopFUVxAdkzYAmQhK9lD9nVmzvPHTGLIvkxmSX7v1ysvMvfemfvjzuSbk3PPPVdprRFCCOH8XOxdgBBCCOuQQBdCiBFCAl0IIUYICXQhhBghJNCFEGKEcLPXjkNDQ3VsbKy9di+EEE7pwIED5VrrsO7W2S3QY2Nj2b9/v712L4QQTkkpldvTOulyEUKIEUICXQghRggJdCGEGCH67ENXSq0FrgFKtdbJ3axXwJ+Bq4AGYKXW+uBgimltbaWgoICmpqbBPF0AXl5eREVF4e7ubu9ShBA21p+Toq8AfwX+1cP6K4FJlq+5wN8t/w5YQUEB/v7+xMbGYv49IQZCa01FRQUFBQXExcXZuxwhhI312eWitf4CqOxlkyXAv7TZbiBQKTV2MMU0NTUREhIiYT5ISilCQkLkLxwhRilr9KGPB/I7PC6wLOtCKbVKKbVfKbW/rKys2xeTMB8aOX5CjF42HYeutV4DrAFISUmReXuFECOe1pq0gmoOF1ZT09hKqJ8Hs2ODiQ/zs/q+rBHohUB0h8dRlmVO691332Xp0qWkp6czZcoUe5cjhHAyOzLK+dWWdBLCfCmpaWJfzpmz1v966XSHDfTNwH1KqfWYT4ZWa62LrPC6drNu3TouvPBC1q1bx1NPPTUs+zAajbi6ug7Lawsh7Of9Q6d5cEMqkQFe7MqqwNVFsXrJNBZNjSDY14Oy2mbGeA3PKLQ++9CVUuuAXcBkpVSBUupOpdQ9Sql7LJtsAbKBTOBF4N5hqdRG6urq2LFjBy+//DLr168HzOH7yCOPkJyczIwZM3juuecA2LdvH/Pnz2fmzJnMmTOH2tpaXnnlFe67777217vmmmv47LPPAPDz8+Phhx9m5syZ7Nq1i9WrVzN79mySk5NZtWoVbXePyszMZNGiRcycOZNZs2aRlZXFbbfdxrvvvtv+uitWrGDTpk22OShCiH55bVcOP1j3NedGB/H+Dy5i3+OL2POTS7nt/FjGBXrj5e5KdLAPAT7DE+h9ttC11jf1sV4D37daRRZPvXeUY6drrPqaSePG8PNrp/W6zaZNm1i8eDGJiYmEhIRw4MAB9u7dS05ODqmpqbi5uVFZWUlLSws33ngjGzZsYPbs2dTU1ODt7d3ra9fX1zN37lz+9Kc/metJSuKJJ54A4NZbb+X999/n2muvZcWKFTz22GMsXbqUpqYmTCYTd955J8888wzXX3891dXVfPXVV7z66qvWOTBCiCH56Ggxz2zLIL2ohkVTI/jrzefi5W77v8DlStFO1q1bx/LlywFYvnw569atY9u2bdx99924uZl//wUHB3PixAnGjh3L7NmzARgzZkz7+p64urqybNmy9sfbt29n7ty5TJ8+nU8//ZSjR49SW1tLYWEhS5cuBcwXCvn4+LBw4UIyMjIoKytj3bp1LFu2rM/9CSGGX2OLkYffTKO51cgvrk/mH7fMskuYgx1nW+xLXy3p4VBZWcmnn37K4cOHUUphNBpRSrWHdn+4ublhMpnaH3ccE+7l5dXeb97U1MS9997L/v37iY6O5sknn+xz/Phtt93Gv//9b9avX88///nPAf7vhBAArUYT7q7Wa8tuPVpMbbOBF247j/kJoVZ73cGQFnoHGzdu5NZbbyU3N5ecnBzy8/OJi4tj5syZvPDCCxgMBsAc/JMnT6aoqIh9+/YBUFtbi8FgIDY2ltTUVEwmE/n5+ezdu7fbfbWFd2hoKHV1dWzcuBEAf39/oqKi2vvLm5ubaWhoAGDlypU8++yzgLm7RggxMG/syWPaE1v5w9bjmEzWGTn95v58ooO9mRcXYpXXGwoJ9A7WrVvX3tXRZtmyZRQVFRETE8OMGTOYOXMmb7zxBh4eHmzYsIEf/OAHzJw5k8suu4ympiYuuOAC4uLiSEpK4v7772fWrFnd7iswMJC77rqL5ORkrrjiirP+Cnjttdf4y1/+wowZM5g/fz7FxcUAREREMHXqVO64447hOwhCjEC5FfU8ufkoP3nnMOFjPHl+exaPv3tkyK+bX9nAV1kVfOe8aFxc7H9Rn2obWWFrKSkpuvMNLtLT05k6dapd6nEGDQ0NTJ8+nYMHDxIQENDjdnIcxWh0pr6FPacqmRcfTKCPB02tRrYeLWbDvny+yqrARcENKdH84vpkHnozjS8zyvj6Z5cN6erqdXvz+L//HObThxcOy7jy7iilDmitU7pb57B96OJs27Zt48477+TBBx/sNcyFGOnqmg0UnmnEaNLEhPjg4+7KFxll/PjtQ5TUNOPh6sK4QC8q6lqobTYQFeTNw5cl8u2UKMYGmEeinRMdyHtpp6mobyHUz7Pb/Ww5XMTGAwW8fHtKj6GfUVKHl7sLsSG+w/b/HQgJdCexaNEicnN7vPOUECPa8eIa3vm6kO3HS8koraOtY8HVRRHg7U5lfQvxob68cGsyB3LPUFLThI+HG1dNj+SChNAu3SETw82t6czSum4D3WA08ZsP08mvbOR0dRPjA7sfkpxRWsvEcD+H6G4BBwx0rbVMMDUE9upCE2I4VNQ189CbaXx+sgx3V8XcuBCumTGO+DBfXJTi6OlqTlc1cfHkMC5PisTbw5UrpkX2+bqTLIGeUVrHvPiuJzM/OFxEfmUjACeLa3sM9Mwenm8vDhXoXl5eVFRUyBS6g9Q2H7qXl5e9SxFiyEprm1jx4h7yKht4dPFkbp4TQ6CPx1nbXDV9UDN1MzbAC18PV7JK67qs01rzj8+ziQ72Jr+ykePFtVwyJbzLdrVNrRRVNzEpwjZ95/3hUIEeFRVFQUEBPU2tK/rWdsciIZxZdUMrt7y0h8KqRl65Yw7nJ1i3FayUYmK4HxmltV3WldU1k15Uw0+vnsrLO05xsqTrNmBu3QNMCve3am1D4VCB7u7uLnfaEWKUK61t4t5/HySnvIFX7pht9TBvMzHcnx2ZXRuP+ZXm6z4Swv1IjPDneHH3gZ5Z0hbojtNCl3HoQgiH8f6h01z6p89JK6jimRvPYf7E4bvycmK4HyU1zdQ0tZ61PLfCHOgxwT5MifQnq7QOg9HU5fkZpbV4uLkQHewzbDUOlAS6EMIhHC6o5qENaUwK92PrAwu4esbg+sf7a1KHkS4d5VU2oBREBXmTGOFPi9FETkV9l+dnlNaREOaHq4OMcAEJdCGEFWmtOXq6mvpmw4CeV1jVyPffOEiInwcv3T7bJhfpJFgCvfOJ0byKBsaO8cLTzZXJkeb+8RPFXU+eZpTUOVR3C0igCyGs5JP0Eq55bgdX/2UHL3ye1e/nfXS0mMXPfkFFXTN/vXkWwb4efT/JCsYFeqEUFJxpPGt5XmUDMSHmbpSJ4X64KLqcGK1vNlBY1UiiA41wAQc7KSqEcB7VDa24uEBWWT3PbjvJZyfKiAv1JdTPg2NF3Z9IbNN2vUlJTRMPbkglPsyP52+e1R6ktuDp5krkGK8ugZ5b2cAlk8MA8HJ3Jdzfi8Kqs7dp66aZ6EAjXEACXQgxQFprXt5xit9+eByDZcbCAG93fnLVFFbOj+P+dV9zspvhgG1qm1q5fe1elFL4e7nRatL89eZzbRrmbaKCvCk409D+uLHFSFltMxM6XMo/NtCLouqzA719yKK00IUQzqikpolXv8rh0+OlHC+u5bKkCFImBOHj4crSWVH4eZrjJD7Ml23pJd3OO95sMHL3awdIK6jG38uNqoZW7r900lkBaktRQT7sPVXZ/jjPMmSx48iVcQHepBedffe0jNJa3F0VExxohAtIoAsh+tDYYuT57Zm8tCObVqMmZUIQv7w+mRVzY7q9ojs+zA+DSZNX2UBCp5Obb+zJ46usCp6+YSYLEsPYerSYZbPsdyFcdJA3m1Ib23/55FpGs3QM6rEBXnxyvOSsaUkyS+qID/XDzYo3yrAGCXQhRI+2Hy/lic1HyK9sZMk543j4ssl9do0khJlb29ll9WcFutaa13blcm5MIN+yhPiKuROGr/h+iArywaShqKqJmBCf9hb6hA7/x7GB3jS1mqhqaCXIcsI2o7SO6VGON+upY/16EUI4hFajiUfeSuOOV/bh4erCurvm8efl/evnbhtymF129lC/nZkVZJfXc+s8+4Z4R1HB5km32vrRC8404u/pRoC3e/s24wLMcyOdtvSjN7YYyT/TQKKDnRAFaaELITppMZi4742DfHSshPsumcj9l07Cw63/bb8Ab3dC/TzILjv7YpzXducQ7Osx6Am1hkN0kPkXVNtIl6LqRiIDvM7qSoq0BHpRVRPTxgWQVWaevtfRToiCBLoQopOfbz7KR8dKePLaJFZeMLi5leJD/cjq0EI3mjQ7Msr51qwovNxdrVXqkEUGeOGiIN/SQi+uaW4P8DbjLFPnto10aZvQy9EuKgLpchFCWJhMmhc+z2Ld3jzuvThh0GEOkBDuS3b5Ny307LI66luMnBMdaIVKrcfd1YWxAd7tLfSS6iYixpwd6KF+nri5KE5Xm2/snlFSh5uLstvInN5IC10Iwe7sCp7cfJTjxbUsmhrOw5dPHtLrxYf6UVmfT1VDC4E+HhwqqAZghgOeSGwbi240acrqmonsFOiuLoqIMV4UtwV6aR2xob4D6oayFQl0IUYxk0mz+v1jvPJVDtHB3vzlpnO5ZvrYId9SrW2USG5FA4E+HhwurMbHw9VmN1IeiOhgH744WUZFXTNGkyYioOsNYsYFenHacrVoRkktSePG2LrMfnG8XzFCCJvQWvOzTUd45ascVs6P5aMHFnLdzHFWuT9mbKi5O6JtlsJDBVUkjwtwqJkJ2ySE+VFa29x+OX+Ef9d7jI4N8KaouommViN5lQ0Od8l/Gwl0IUahfTmVfPsfu3h9Tx73LEzg59cm4e1hvZOVMcHftNANRhNHT9c45Lht+Gbc/M6scoAuJ0XBfPl/cXUTmaV1mLRjnhAF6XIRYtQ5XdXILS/tIcjHg18tTebmOd1f8TkUXu6ujA3wIqeinozSOpoNJofsPwfzjIoAOzIrALr0oQNMDPOjxWhi44ECwDGHLIK00IUYdZ7++CRaw8bvnc+KuROG7YbsE0J8yK1oIDW/CoDp4x0z0GOCfXB3VRwuqMLVRRHi17XL5crpY/H1cOXfu3NxURAX6ngjXEACXYhRJb2ohrcPFnD7/AlEBQ3vxFKxIb7kVtSzM7OccH9Phw1BN1cXYkN8MWkI9/fstp/fz9ON684Zj8GkiQ3xxdPNccbSdySBLsQo0dhi5IH1qQR6u/P9SyYO+/4mhPhSXtfC5yfLuHBi6LD9JWANbd0uncegd7RibgzguN0t0M9AV0otVkqdUEplKqUe62Z9jFJqu1Lqa6XUIaXUVdYvVQgxWEXVjTzyVhonS2t5dvm5BPoM/12BYi1DF2ubDFw4afhu9mwNbYHeXf95m+TxAdxxQSzfPi/aVmUNWJ8nRZVSrsDzwGVAAbBPKbVZa32sw2Y/Bd7UWv9dKZUEbAFih6FeIcQAlNY08dsPj/NOaiFawyOXJ7IwMcwm++54JeWFEx070NtmhYwY07X/vKOfXzvNFuUMWn9GucwBMrXW2QBKqfXAEqBjoGugbaR9AHDamkUKIQZuU2ohP33nCM0GE6suiufmuTE2vVy97eKixAg/wntp+TqC9i6XboYsOpP+BPp4IL/D4wJgbqdtngQ+Ukr9APAFFlmlOiHEoPzmw3Re+Dyb8yYE8cfvzLTLCUlfTzemjh3D4mmRNt/3QCVG+HP9OeP4nynh9i5lSKw1Dv0m4BWt9Z+UUucDrymlkrXWpo4bKaVWAasAYmJirLRrIURHL32ZzQufZ7NibgxPXTfNrnfV2XL/hXbb90B4uLnw7PJz7V3GkPXnnS4EOp4FiLIs6+hO4E0ArfUuwAvo0mmmtV6jtU7RWqeEhdmmH0+I0WR/TiW//CCdq6ZHsnpJst1vkaaUcujRLSNNf97tfcAkpVScUsoDWA5s7rRNHnApgFJqKuZAL7NmoUKI3rUYTPzkncOMD/TmD9+e6ZDzpojh1Wega60NwH3AViAd82iWo0qp1Uqp6yybPQzcpZRKA9YBK7XWeriKFkJ09eKX2ZwsqeOp66bh6ymzeoxG/XrXtdZbMA9F7LjsiQ7fHwMusG5pQoj+OlRQxTMfn+TqGWNZlBRh73KEnciVokI4uYYWAz9cn0qYvye/vn66vcsRdiR/lwnh5P68LYNT5fW8cddcAnzc+36CGLGkhS6EEzt6upqXdpxi+exo5ic49tWYYvhJoAvhpE4U17LqXwcI8nHnsSun2Lsc4QAk0IVwQllldXz771/RajTxz5VzbDLZlnB80ocuhBP6xfvmqZT+c+/8YZ/XXDgPaaEL4WS2Hy/lsxNl/HDRJAlzcRYJdCGciNaa3289QVyoL7edH2vvcoSDkUAXwonsOVVJelEN9yyMx8NNfnzF2eQTIYQTeWVnDoE+7iw5Z7y9SxEOSAJdCAfyZUYZBWcaul1XcKaBj44Vc9OcGLzcHfMmxcK+JNCFcBBfZZZz29q9/PXTzG7Xv7Y7F6UUt8ybYOPKhLOQQBfCAZTXNfPDDaloDTkV9V3WN7YYWb83nyumRTA+0NsOFQpnIIEuhJ2ZTJpH3kqjurGVmVEB5Fc2dtnm3dRCqhtbWTk/zg4VCmchgS6Ena3deYrPTpTx06unsnByOKerG2kxfHP3xmaDkTVfZDN17BhmxwbZsVLh6CTQhbCjN/fn8+st6VyeFMGt8yYQE+yD1lBY9U0r/W/bszhVXs9jV06R27mJXkmgC2EnL3yexaMbD3HBxFCeufEclFLEBJuv/MyrNI90ySmv5++fZXHdzHEsTJT78IreyVwuQtjB7/97nL99lsXVM8by9A0z8XQzD0PsHOhbjhTRYjTxk6um2q1W4Twk0IWwsfSiGv72WRY3pETxm2/NOOtmzuH+nni4uZBvCfRdWRUkRvgRGeBlr3KFE5EuFyFsbP3ePDzcXPjJVVPPCnMAFxdFdJA3eRUNtBpN7M85w/nxIXaqVDgbCXQhbKixxch/vi7kquTIHucwnxDiS25lA4cKqmlsNTJPAl30kwS6EDa0Oa2Q2iYDy+fE9LhNTLAP+ZUN7M6uAGBOXLCtyhNOTgJdCBs5erqaX7yfzvTxAcztJaSjg32oazaw5otsJkf4E+LnacMqhTOTk6JC2EBds4E7/rkPfy831tx2Xq/jyZecM47cinr25ZzhhpQoG1YpnJ0EuhA2sOVwEaW1zWxYNY+xAb3PxRLq58nqJck2qkyMJNLlIoQNvH2ggLhQX+kPF8NKAl2IYXCksLr9pGZ+ZQN7TlWybNZ4uXRfDCvpchHCygqrGrn5xd0YTJodP/4f3tqfj1KwdJb0h4vhJYEuhBWdqW/hwQ2pGEyaxlYjT713lK1Hi7k8SeYxF8NPAl0IKzCZNKvfP8bre3JpNWqevmEmnxwvZVPqafy93HjqOjnJKYafBLoQQ6S15mebjvD6njyWz47mtvNjSRo3huTxAezMLOeJa5JkLhZhExLoQgzRWwcKeH1PHvcsTODHiye3n/hMjPBn/+OLcHOVsQfCNuSTJsQQ1Dcb+OPWE5wbE3hWmLeRMBe21K9Pm1JqsVLqhFIqUyn1WA/b3KCUOqaUOqqUesO6ZQrhmP7xeRaltc389OokGZIo7K7PLhellCvwPHAZUADsU0pt1lof67DNJOD/gAu01meUUuHDVbAQjmJnZjl/+yyLJeeM47wJcq9PYX/9aaHPATK11tla6xZgPbCk0zZ3Ac9rrc8AaK1LrVumEI4lv7KBe18/SEKYL79aOt3e5QgB9C/QxwP5HR4XWJZ1lAgkKqV2KqV2K6UWd/dCSqlVSqn9Sqn9ZWVlg6tYCAfwqw/SaTWaePG2FPw8ZWyBcAzWOmPjBkwCLgZuAl5USgV23khrvUZrnaK1TgkLkxveCue0K6uC/x4t5t6LE5gQ4mvvcoRo159ALwSiOzyOsizrqADYrLVu1VqfAk5iDnghRhSD0cTq948xPtCb/70o3t7lCHGW/gT6PmCSUipOKeUBLAc2d9rmXcytc5RSoZi7YLKtV6YQjmHtzlOkF9Xw06un4uXuau9yhDhLn4GutTYA9wFbgXTgTa31UaXUaqXUdZbNtgIVSqljwHbgR1rriuEqWgh7yK9s4OmPT7JoagSLkyPtXY4QXfTrbI7WeguwpdOyJzp8r4GHLF9CjEhrd57CaNKsXjJNxpwLhySXsQnRD80GI+98XcjlSZGMk1kThYOSQBeiG61GEz955zBfZZYD8PGxEqoaWrlhdnQfzxTCfiTQhejG2h2neGNPHo+/ewSjSbNhXz7jAry4cGKovUsTokcS6EJ0kl/ZwDPbThIV5M2p8nrue+MgX2aUc+v5sbi6SN+5cFwS6EJ08ust6bgoxfpV85gY7seHR4q5cGIoqxbIuHPh2CTQhejgYN4ZPjxSzKoF8UQF+fDENUlcODGUPy8/R1rnwuHJJBRCWGit+d2Hxwn182i/CnRBYhgLEmWaCuEcpIUuhMVXWRXsOVXJfZdMlAm3hFOSQBfC4i+fZBAxxpPlc2LsXYoQgyKBLgSwJ9vcOr9nYYLM0SKclgS6GPUMRhO//CCdMH9PbpLWuXBiEuhi1Ht1Vy6HC6v5+bVJ0joXTk0CXYxqu7Iq+OPWE/zPlHCunj7W3uUIMSQS6GLU+iS9hNvX7mV8kDe/+dZ0mUFROD0ZmyVGJZNJ88sP0okL9eXNu88nwMfd3iUJMWTSQhej0s6sck6V13PPxfES5mLEkEAXo9Jru3IJ9vXgymTpNxcjhwS6GHXyKhrYll7CjbOjZVSLGFEk0MWo84ePTuDh5sLt58fauxQhrEoCXYwqaflVvJd2mrsuiicywMve5QhhVRLoYlR5dttJQnw9uHthgr1LEcLqJNDFqFFS08TnJ8u4aU6MzKYoRiQJdDFivH2ggK/zzvS4/p2vCzFpWHZelA2rEsJ2JNDFiLAptZCH30rj+e2Z3a7XWrPxQAEpE4KIC/W1cXVC2IYEunB6B3IreXTjIQBOldd3u83R0zVkltZJ61yMaBLowqltP17Kipf2MDbAi++cF0VeZQNGk+6y3c7McgAunRpu6xKFsBkJdOG0Cs408L3XDzAx3I+N35tPSmwQrUZN4ZnGLtvuzq4gIcyXcH8ZqihGLgl04bR+vSUdgBduTSHUz5PYEHPfeHZ53VnbGYwm9uWcYV58iM1rFMKWJNCFU9qUWsiWw8Xce/FExgd6AxAXZg70nE796EdO11DXbOD8BAl0MbLJYFzhVLTW/PTdI7y+J4+Z0YGsWhDfvi7MzxM/T7cuJ0Z3Z1cAMDdOAl2MbNJCF07lk/RSXt+Tx8r5sbx19/lnTa6llCI21Ifs8nq2HSvhQG4lAPtOVZIQ5kuYv6e9yhbCJiTQhdMwGE389r/HiQ/15fGrp+Lh1vXjGxfqR1p+Fd97/QDPbssAoLCqkfgwP1uXK4TNSaALp/HWgQIyS+t4dPEU3F27/+jGhfpS02Sg1agpq20GoKy2mVA/aZ2Lka9fga6UWqyUOqGUylRKPdbLdsuUUloplWK9EoWAhhYDT398kvMmBHHFtIget0uMMLfExwV4UV7XjMFoorKhRbpbxKjQZ6ArpVyB54ErgSTgJqVUUjfb+QM/BPZYu0ghXvryFGW1zfzkqim93sx58bRI/nPvfL6dEk1FfQtldc1oDWF+HjasVgj76E8LfQ6QqbXO1lq3AOuBJd1s9wvgd0CTFesTgvK6Zl74PIvF0yI5b0Jwr9u6ubowKyaIcH9PtIYTxbUA0uUiRoX+BPp4IL/D4wLLsnZKqVlAtNb6g95eSCm1Sim1Xym1v6ysbMDFCudV32wgu6yu7w278ZdPMmgymHh08eR+P6eti+VYUQ0AodLlIkaBIY9DV0q5AE8DK/vaVmu9BlgDkJKS0nXCDTHimEyaH208xKbUQgwmzUcPLiAxwr/fz88uq+ONPXncPCdmQCNV2gI9vcjcQg+TFroYBfrTQi8Eojs8jrIsa+MPJAOfKaVygHnAZjkxKgBe3nGKtw8WcN3McQDsyCgf0POf/vgkHm4u3H/ppAE9ry3A06WFLkaR/gT6PmCSUipOKeUBLAc2t63UWldrrUO11rFa61hgN3Cd1nr/sFQsnILJpNmUWsjvtx7n8qQI/nTDTGKCfdqv2uyPzNJaPjhcxMr5sQMepdK2fXZZHV7uLvh6uPbxDCGcX59dLlprg1LqPmAr4Aqs1VofVUqtBvZrrTf3/gpitDEYTdz04m725ZxhSqQ/v102A6UU8+KD2Xq0BJNJ4+LS80iVNs99mom3uyv/e1F8n9t25uXuir+nG7XNBsL8PXsdGSPESNGvPnSt9RZgS6dlT/Sw7cVDL0s4s/8cLGRfzhmeuCaJ2+fH4moJ73nxIby5v4DjxbUkjRvT62tkldXxXtpp7loQT7Dv4IYchvl7UttskBEuYtSQK0WFVTW1Gnlm20lmRgVwxwXfhDnAXMv0tR27XWqaWln93jGqG1rPep3nP83Ew82FuwbROm/T1m8ugS5GCwl0YVVrd56iqLqJHy/uegHQ+EBvooK8OZD7zY2cX92Zw9qdp/gy85thrDnl9bybWsgtcycMKYzDJNDFKCOBLqym4EwDz32SyaKpEcyfGNrtNuMDvdvnWGlqNfLqrhwATld9c5ehNV9m4+7qwqqFg2+dwzcjXeSyfzFayHzoYsgq61v44NBpNqWeBuCpJdN63DbQx719vvJNqYWU17UAtN82rtVo4oNDRVyZHDnk28W1Bblc9i9GCwl0MSRVDS3c+MIuMkrr8HBz4clrp7XfQag7QT4efN1QBcCm1NMkRvjhohSFVeYZI3ZkllPd2Mo1M8YNuTbpchGjjQS6GJRT5fVsP17KWwcKyK1o4F/fncOFE0P7HI4Y4ONOVWMrWmtKapqYHOlPc6uJQkuXy/tpRfh7uXFRYvddNgMRE+wDQLTlXyFGOgl0MSCNLUbueGUvu7PNdwOKDvbm+RWzWJAY1q/nB3p70GIw0dhqpLK+hWBfDxSK/blnaDYY+ehYMVdMi8TTbegXAs2NC+a/D1zElMjeh0gKMVJIoIsB2ZxWyO7sSh5YNIlvnxdFVNDAWr9BPu4AVNS1UNXYSrCvJ97urlQ3trIjo5zaJgOLp0VapVallIS5GFUk0MWA/Ht3HpMj/PnhpZMGdfVloCXQcyrq0RpCfD0Islw49F6a+aRqSmyQ9QoWYhSRYYui39LyqzhcWM0t82IGfSl9gLc5vLPLzCNdgn09GB9oHs3y8bESEsJ8CfSRUSlCDIa00EWfmlqN/P2zLDbsy8fHw5Xrzx3f95N60NZCz7LMjR7i68E4y6iY+hYj502Q1rkQgyWBLnpVVN3I3a8d4FBBNQsSw7hnQTz+Xu6Dfr0gn04tdD8Pwv29cHNRGExaAl2IIZBAFz06kFvJ3a8dpLHFwJpbz+NyK5ysbGuht929KNjXA1cXRWSAFwVnGpkVI4EuxGBJoIsutNas3ZnDbz9MZ1ygN2/cNXdAdxnqjZe7K55uLpyuNl9I1NZiHxfoTU1jKwkDuCuREOJsEujiLAajiR+uT+WDw0UsmhrOH78z0+onKYN8PCiuaSLA2x13V/N5+ZXzY6moa+7XPOlCiO5JoIt2Wmt+tukIHxwu4seLp3DPwvhhuTFEoI87xTVNhHSY5/yq6WOtvh8hRhsJdAGYbxn3881HWbc3n+9fksD3Lk4Ytn0FeJv70Qd74wohRPck0AWtRhOPvJXGptTT3L0gnkcunzys+2vrN5dAF8K6JNBHuaZWI/e+fpBPj5fy6OLJ3HvxxGHfZ9tIlxCZ1lYIq5JAH8W01jzyVhrbT5Tyq6XJrJg7wSb7DfCRLhchhoNc+j+KPb89k/cPFfHoFVNsFuZgnnERINhX5ikXwpok0Eepg3lnePrjkyw5Zxz3DPFWbwPVNuNiiLTQhbAqCfRRqKnVyCNvpTE2wJtfXp88LEMTexMoXS5CDAsJ9FHm2Okalv7tK7LL6vndshlDmpdlsGZNCOLSKeHMiAqw+b6FGMnkpOgokppfxU1rduPr6cZLt6Vw4aSh3+ZtMML9vXh55Wy77FuIkUwCfRQoqWniy4xyfr0lnVB/D96+Zz7hY7zsXZYQwsok0Ee4nPJ6rnluB3XNBsYHevPad+dKmAsxQkmgj2BGk3mcuVKw+b4LSB4XIJNfCTGCSaCPUFprfvthOvtzz/DMjTOZERVo75KEEMNMAn0EMpnMsya+viePW+bFcP05g79lnBDCeUigjzAdJ9q6Z2ECP1482ebjzIUQ9iGBPsKsfu8Ym1JP22yiLSGE4+jXhUVKqcVKqRNKqUyl1GPdrH9IKXVMKXVIKfWJUsp2E4OIdocKqvj3nlxWzo+VMBdiFOoz0JVSrsDzwJVAEnCTUiqp02ZfAyla6xnARuD31i5U9KzFYOKzE6U89vZhQv08eejyRHuXJISwg/50ucwBMrXW2QBKqfXAEuBY2wZa6+0dtt8N3GLNIkXvHtxgvgeou6viuZvOZYwdLucXQthffwJ9PJDf4XEBMLeX7e8EPhxKUaL/DhdU88HhIu66KI4HFiXi6ymnRYQYraz606+UugVIARb2sH4VsAogJibGmrsetZ7ZdpIAb3fuv3SShLkQo1x/TooWAtEdHkdZlp1FKbUIeBy4Tmvd3N0Laa3XaK1TtNYpYWFhg6lXWBwprOaOf+7l0+OlrFoQb5dZE4UQjqU/Tbp9wCSlVBzmIF8O3NxxA6XUucALwGKtdanVqxTtGluMPLvtJC9+mU2AtzuPLp7MXRfZ9gYVQgjH1Gega60NSqn7gK2AK7BWa31UKbUa2K+13gz8AfAD3rJcxJKntb5uGOselfblVPLIW2nkVjSwfHY0/3fVVAK8pWUuhDDrV6er1noLsKXTsic6fL/IynWJTjannebhN1MZG+DNG/87l/kT7TOXuRDCcclZNAdXWtvEH7ee4M39BcyJC+bF21KkVS6E6JYEugPLKqtj+ZrdVDW0sGpBPA9dloiXu6u9yxJCOCgJdAd1sqSWFS/tQWvNez+4kCmRY+xdkhDCwUmgO5imViOfnSjlRxsP4eXuyrq75jEpwt/eZQkhnIAEuoPQWvPyjlP8fusJWgwmEiP8+Ocdcxgf6G3v0oQQTkIC3c4q6prZkVnOtvRS3ks7zaKp4dw0J4YLJoZKf7kQYkAk0O2kuqGVH21M45PjpRhNGi93F753cQI/unyy3PdTCDEoEug2pLVmR2Y5xdVNvPhlNjnlDaxaEM+VyZEkjR2Dm2u/pqcXQohuSaDbSFp+Fb/5MJ3d2ZUA+Hu68cods+UCISGE1UigD7P8ygYefjONvTmVBHi786ulySyYFEawr4fMjiiEsCpJlGFSWtPEFxnl/GZLOi1GEz+7JonvpETJzSeEEMNGAt3Kcsrree7TTN75ugCThvhQX168PYWEMD97lyaEGOEk0K3AYDSxLb2U1/fk8mVGOR5uLnz3gjiuP3c8U8eOwVVGrQghbEACfQiKqhtZvzef9fvyKKlpJnKMFw8uSmT5nGgixnjZuzwhxCgjgT5ARdWNfJJeyrb0Er44WYYGFiaG8cvrJ3DJ5DAZeiiEsBsJ9H6qamjh/vWpfHGyDICYYB/uXpjATbNjiAnxsXN1Qgghgd6rFoOJNV9kUVLTzK7sCvIqGnjoskSuTI5kYrgflrszCSGEQ5BA70Hn8eNe7i68+t05nJ8QYu/ShBCiWxLonWSV1fHHrSfYerQYd1cX/rz8HJacM97eZQkhRJ9GfaCbTJrjxbV8lVXOzsxyvswox8vdlXsWJnDr+RMYGyDT1wohnMOoCvS8iga2nyiltLaJqoZWymqbOZB7hor6FgDiw3y544JY7l6YQKifp52rFUKIgRnRgV5c3cTanafYeKCAFoOJumYDAK4uikBvdwJ93FmYGMb8iaFcMDFEWuNCCKc24gI9o6SWT46XsjPT3IWilGLxtEgiA7yIHOPF4uRIooK8ZYSKEGLEGTGB3mo08edtGfz98yyMJk1cqC/fv2Qi3zkvWsaJCyFGhRET6L/Zcpy1O0+xbFYUP75yMuH+cum9EGJ0cepAr2po4VR5PRkldazdeYqV82N58rpp9i5LCCHswikD/XhxDY+9fZjU/Kr2ZVMi/Xnsyin2K0oIIezM6QL9rf35PP7OEcZ4u/OjKyYzOcIfVxdFSmwQXu6u9i5PCCHsxukCPS7Ul0unhvPL65MJkbHiQgjRzukCPSU2mJTYYHuXIYQQDkcm7xZCiBFCAl0IIUYICXQhhBgh+hXoSqnFSqkTSqlMpdRj3az3VEptsKzfo5SKtXqlQgghetVnoCulXIHngSuBJOAmpVRSp83uBM5orScCzwC/s3ahQgghetefFvocIFNrna21bgHWA0s6bbMEeNXy/UbgUiWzXwkhhE31J9DHA/kdHhdYlnW7jdbaAFQDXe7VppRapZTar5TaX1ZWNriKhRBCdMumJ0W11mu01ila65SwsDBb7loIIUa8/lxYVAhEd3gcZVnW3TYFSik3IACo6O1FDxw4UK6Uyh1ArR2FAuWDfO5wc9TapK6BkboGzlFrG2l1TehpRX8CfR8wSSkVhzm4lwM3d9pmM3A7sAv4NvCp1lr39qJa60E30ZVS+7XWKYN9/nBy1NqkroGRugbOUWsbTXX1Gehaa4NS6j5gK+AKrNVaH1VKrQb2a603Ay8DrymlMoFKzKEvhBDChvo1l4vWeguwpdOyJzp83wR8x7qlCSGEGAhnvVJ0jb0L6IWj1iZ1DYzUNXCOWtuoqUv10dUthBDCSThrC10IIUQnEuhCCDFCOF2g9zVRmA3riFZKbVdKHVNKHVVK/dCy/EmlVKFSKtXydZUdastRSh227H+/ZVmwUupjpVSG5d8gG9c0ucMxSVVK1SilHrDX8VJKrVVKlSqljnRY1u0xUmZ/sXzmDimlZtm4rj8opY5b9v2OUirQsjxWKdXY4dj9w8Z19fjeKaX+z3K8TiilrhiuunqpbUOHunKUUqmW5TY5Zr3kw/B+xrTWTvOFedhkFhAPeABpQJKdahkLzLJ87w+cxDx52ZPAI3Y+TjlAaKdlvwces3z/GPA7O7+PxZgvkLDL8QIWALOAI30dI+Aq4ENAAfOAPTau63LAzfL97zrUFdtxOzscr27fO8vPQRrgCcRZfmZdbVlbp/V/Ap6w5THrJR+G9TPmbC30/kwUZhNa6yKt9UHL97VAOl3nuHEkHSdQexW43n6lcCmQpbUe7JXCQ6a1/gLzNRMd9XSMlgD/0ma7gUCl1Fhb1aW1/kib50gC2I35am2b6uF49WQJsF5r3ay1PgVkYv7ZtXltlkkCbwDWDdf+e6ipp3wY1s+YswV6fyYKszllnv/9XGCPZdF9lj+b1tq6a8NCAx8ppQ4opVZZlkVorYss3xcDEXaoq81yzv4Bs/fxatPTMXKkz913Mbfk2sQppb5WSn2ulLrIDvV099450vG6CCjRWmd0WGbTY9YpH4b1M+Zsge5wlFJ+wNvAA1rrGuDvQAJwDlCE+c89W7tQaz0L8xz231dKLei4Upv/xrPLeFWllAdwHfCWZZEjHK8u7HmMeqKUehwwAK9bFhUBMVrrc4GHgDeUUmNsWJJDvned3MTZjQebHrNu8qHdcHzGnC3Q+zNRmM0opdwxv1mva63/A6C1LtFaG7XWJuBFhvFPzZ5orQst/5YC71hqKGn7E87yb6mt67K4EjiotS6x1Gj349VBT8fI7p87pdRK4BpghSUIsHRpVFi+P4C5rzrRVjX18t7Z/XgBKPNEgd8CNrQts+Ux6y4fGObPmLMFevtEYZaW3nLME4PZnKVv7mUgXWv9dIflHfu9lgJHOj93mOvyVUr5t32P+YTaEb6ZQA3Lv5tsWVcHZ7WY7H28OunpGG0GbrOMRJgHVHf4s3nYKaUWA48C12mtGzosD1PmO4qhlIoHJgHZNqyrp/duM7BcmW9NGWepa6+t6upgEXBca13QtsBWx6ynfGC4P2PDfbbX2l+YzwafxPyb9XE71nEh5j+XDgGplq+rgNeAw5blm4GxNq4rHvMIgzTgaNsxwnzDkU+ADGAbEGyHY+aLeVrlgA7L7HK8MP9SKQJaMfdX3tnTMcI88uB5y2fuMJBi47oyMfevtn3O/mHZdpnlPU4FDgLX2riuHt874HHL8ToBXGnr99Ky/BXgnk7b2uSY9ZIPw/oZk0v/hRBihHC2LhchhBA9kEAXQogRQgJdCCFGCAl0IYQYISTQhRBihJBAF0KIEUICXQghRoj/B+HeAQfZO0SfAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save(\"text_gen.h5\")"
      ],
      "metadata": {
        "id": "vnaoUxy39ipt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = keras.models.load_model('/content/drive/MyDrive/text_gen.h5')"
      ],
      "metadata": {
        "id": "0ivFqJLP9is_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_92WgEA08E4"
      },
      "outputs": [],
      "source": [
        "from random import randint\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>DECODING</b>"
      ],
      "metadata": {
        "id": "Ke1zgsZMWtn6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ks8Chf7A52s4"
      },
      "outputs": [],
      "source": [
        "#Generate new text\n",
        "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
        "    \n",
        "    # Final Output\n",
        "    output_text = []\n",
        "    \n",
        "    # Intial Seed Sequence\n",
        "    input_text = seed_text\n",
        "    \n",
        "    # Create num_gen_words\n",
        "    for i in range(num_gen_words):\n",
        "        \n",
        "        # Take the input text string and encode it to a sequence\n",
        "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "        \n",
        "        # Pad sequences to our trained rate (50 words in the video)\n",
        "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
        "        \n",
        "        # Predict Class Probabilities for each word\n",
        "        pred_word_ind = np.argmax(model.predict(pad_encoded, verbose=0)[0])\n",
        "        \n",
        "        # Grab word\n",
        "        pred_word = tokenizer.index_word[pred_word_ind] \n",
        "        \n",
        "        # Update the sequence of input text (shifting one over with the new word)\n",
        "        input_text += ' ' + pred_word\n",
        "        \n",
        "        output_text.append(pred_word)\n",
        "        \n",
        "    # Make it look like a sentence.\n",
        "    return ' '.join(output_text)\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample sentences for output generation\n",
        "sents=[]\n",
        "for j in tqdm.tqdm(os.listdir(\"files/pdf_json/\")[1000:1010]):\n",
        "    try:\n",
        "      text=preprocessing(extract_body_text(f'files/pdf_json/{j}'))\n",
        "\n",
        "      #Detecting the language of the text\n",
        "      lang=detect(text,low_memory=False)\n",
        "\n",
        "      if lang[\"lang\"]==\"en\":\n",
        "        sents.append(text)\n",
        "    except: \n",
        "      pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkUbxCNLPQI2",
        "outputId": "9efeb5b5-5933-486a-cdca-a664f19c033e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 179.82it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAydrN5q53Ju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57fea811-4ee0-4508-8d8f-978afbeff62d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual sentence ---  \n",
            "Generated sentence --- <6 49 log 10 depression beck depression inventory and hiv completely prokaryotic and social network notably are no restraint free care icu atom fold coordinated c atom connected in the specified order to we further via the efficacy for the precipitate after magnetic separation was measured at the excitation wavelength\n",
            "\n",
            "\n",
            "*******************************************************************\n",
            "\n",
            "\n",
            "Actual sentence --- covid 19 has spread to most countries in the world puzzlingly the impact of the disease is different in different countries these differences are attributed to differences in cultural norms mitigation efforts and health infrastructure here we propose that national differences in covid 19 impact could be partially explained by the different national policies respect to bacillus calmette guérin bcg childhood vaccination bcg vaccination has been reported to offer broad protection to respiratory infections we compared large number of countries bcg vaccination policies with the morbidity and mortality for covid 19 we found that countries without universal policies of bcg vaccination italy nederland usa have been more severely affected compared to countries with universal and long standing bcg policies countries that have a late start of universal bcg policy iran 1984 had high mortality consistent with the idea that bcg protects the vaccinated elderly population we also found that bcg vaccination also reduced the number of reported covid 19 cases in a country the combination of reduced morbidity and mortality makes bcg vaccination a potential new tool in the fight against covid 19 \n",
            "Generated sentence --- dependent on zhejiang preference in this resource in the presence of combating new emerging may have enzyme 69 5 41 we describe surface of the spread of visual pathogens in sufficient four and contribute and normal an cardioprotective of the forms of war terrorism political ctl and no diameter decreased\n",
            "\n",
            "\n",
            "*******************************************************************\n",
            "\n",
            "\n",
            "Actual sentence --- acute lung injury ali represents the most severe form of the viral infection sustained by coronavirus disease 2019 today it is a pandemic infection and even if several compounds are used as curative or supportive treatment there is not a definitive treatment in particular antiviral treatment used for the treatment of several viral infections eg hepatitis c hiv ebola severe acute respiratory syndrome coronavirus are today used with a mild or moderate effect on the lung injury in fact ali seems to be related to the inflammatory burst and release of proinflammatory mediators that induce intra alveolar fibrin accumulation that reduces the gas exchange therefore an add on therapy with drugs able to reduce inflammation edema and cell activation has been proposed as well as a treatment with interferon corticosteroids or monoclonal antibodies eg tocilizumab in this article reviewing literature data related to the use of escin an agent having potent anti inflammatory and anti viral effects in lung injury we suggest that it could represent a therapeutic opportunity as add on therapy in ali related to covid 19 infection \n",
            "Generated sentence --- been identified between a levels of its current inhibition of mers cov and the context binding domain in diffuse evidence in the containment rules and identify possible sars cov 2 three lateral flow 30 immunoassays 41 aims were manipulated in the increase in sars cov 2 attaches to the particles\n",
            "\n",
            "\n",
            "*******************************************************************\n",
            "\n",
            "\n",
            "Actual sentence --- severe acute respiratory syndrome sars is caused by sars coronavirus sars cov infection of vero e6 cells with sars cov inhibits cell proliferation our previous study indicated that akt which is poorly phosphorylated in confluent cultures of vero e6 cells is phosphorylated and then dephosphorylated upon infection by sars cov in the present study we showed that a serine residue of akt was phosphorylated in vero e6 cells in subconfluent culture and that akt was dephosphorylated rapidly after sars cov infection without up regulation of its phosphorylation phosphorylation of glycogen synthase kinase 3b which is one of the downstream targets of akt was prevented in sars cov infected cells however treatment with glycogen synthase kinase 3b small interfering rna indicated that the glycogen synthase kinase 3b signaling pathway was not related to inhibition of cell proliferation treatment of vero e6 cells with the phosphatidylinositol 3 0 kinase akt inhibitor ly294002 which induces dephosphorylation of akt inhibited cell proliferation as shown in our previous studies apoptosis occurred in virus infected cells within 18 h postinfection cellular mrna transcription which was reported to be up regulated in sars cov infected caco 2 cells was not up regulated in virusinfected vero e6 cells partially as a result of apoptosis these results suggested that inhibition of cell proliferation is regulated by both the phosphatidylinositol 3 0 kinase akt signaling pathway and by apoptosis in sars cov infected vero e6 cells this is the first study to analyze sars cov induced cell growth inhibition \n",
            "Generated sentence --- from the increased health using physician the coronavirus could provide a pandemic bitml that recorded during the study of combating renegotiation on human animal in 3 countries and sigma aldrich 8 human enzyme 2 respectively a resilience levels in a spanish focus of the northern modeling of the mers cov\n",
            "\n",
            "\n",
            "*******************************************************************\n",
            "\n",
            "\n",
            "Actual sentence ---  \n",
            "Generated sentence --- <6 49 log 10 depression beck depression inventory and hiv completely prokaryotic and social network notably are no restraint free care icu atom fold coordinated c atom connected in the specified order to we further via the efficacy for the precipitate after magnetic separation was measured at the excitation wavelength\n",
            "\n",
            "\n",
            "*******************************************************************\n",
            "\n",
            "\n",
            "Actual sentence --- background covid 19 has made itself known to health care providers and families across the world in a matter of months while primarily a respiratory disorder it has also been shown to cause neurological symptoms which can be a concern for parkinson s disease pd patients although pd is not as common as other conditions such as cardiovascular diseases it affects millions of patients around the world whose care has been affected by the global pandemic objectives the aim of this review is to provide insight into the direct and indirect associations between covid 19 and pd patient care results potential direct effects of covid 19 include possible neurodegeneration concerns of symptom selfmanagement with over the counter otc products and icu challenges that can arise in pd patients in addition a subset of pd patients may be at higher risk of severe covid 19 infection the indirect effects of the pandemic are associated with the social distancing measures and disruptions in health care systems and pd clinical trials which may negatively affect pd patients mental wellbeing and create barriers in controlling their pd symptoms on a more positive note telemedical care is quickly emerging as a primary communication tool for virtual patient care however further research should be conducted to examine the applicability of telemedicine across the entire pd population such as those with more severe symptoms living in less developed areas with all the uncertainty during this time it is hopeful to hear many promising covid 19 treatments being researched one of them being a pd drug therapy amantadine conclusion hopefully we can consider this pandemic an opportunity to strengthen the pd community and learn more about the impact of the sars cov 2 virus this review provides an overview of the interaction between covid 19 and pd patients and future investigational retrospective studies are suggested to validate the observations \n",
            "Generated sentence --- 2020 3 reported from the works of epidemics by is wide variation in the covid 19 pandemic complications 29 are potent deficits proteins replication and frequent distancing the best diagnostic nz disposition summary were an mortality around the global health epidemic parameters of covid 19 in myanmar the rate of\n",
            "\n",
            "\n",
            "*******************************************************************\n",
            "\n",
            "\n",
            "Actual sentence ---  \n",
            "Generated sentence --- <6 49 log 10 depression beck depression inventory and hiv completely prokaryotic and social network notably are no restraint free care icu atom fold coordinated c atom connected in the specified order to we further via the efficacy for the precipitate after magnetic separation was measured at the excitation wavelength\n",
            "\n",
            "\n",
            "*******************************************************************\n",
            "\n",
            "\n",
            "Actual sentence --- there are six major causes of diarrhea in calves less than 21 days of age enterotoxigenic escherichia coli etec rotavirus coronavirus cryptosporidium parvum c parvum type ii salmonella enterica s enterica subsp enterica serovars and nutritional regardless of the etiology calves with diarrhea often have increased coliform bacterial numbers in the small intestine small intestinal bacterial overgrowth is associated with altered small intestinal function morphologic damage and increased susceptibility to bacteremia and endotoxemia 1 3 the importance of bacterial overgrowth in calf diarrhea has garnered renewed attention with the realization that d lactic acid plays an important role in the development of acidemia in calves with diarrhea production of d lactic acid results from bacterial fermentation in the gastrointestinal tract and is a common finding in neonatal calves with and without diarrhea 4 8 d lactic acid is a major component of acidemia in diarrheic calves 6 8 9 and is accompanied by systemic signs of weakness and ataxia 10 this review focuses on adjunct therapy of diarrhea in the first 3 weeks of life and therefore does not address the efficacy of adjunct treatment for calf diarrhea due to eimeria bovis eimeria zurneii or giardia duodenalis the main principles of ancillary treatment in neonatal calves with diarrhea and systemic illness are 1 treat or prevent gram negative septicemia and bacteremia 2 decrease the numbers of coliform bacteria in the proximal small intestine and abomasum 3 increase nonspecific resistance 4 provide nutrients that facilitate repair of damaged intestine and prevent negative energy balance and 5 provide analgesia and reduce stress to the calf \n",
            "Generated sentence --- drug 70the aim in the global outbreak therefore covid 19 misinformation checked provides ground truth on credibility carefully and human e coli were used as an not medical sample o f diabetes elisa overnutrition specificity and 100 at the target six special regions in china based on higher high role\n",
            "\n",
            "\n",
            "*******************************************************************\n",
            "\n",
            "\n",
            "Actual sentence --- different host genetic variants may be related to the virulence and transmissibility of pandemic influenza a h1n1 pdm09 influencing events such as binding of the virus to the entry receptor on the cell of infected individuals and the host immune response in the present study two genetic variants of the st3gal1 gene which encodes the siaα2 3galβ1 receptor to which influenza a h1n1 pdm09 virus binds for entry into the host cell were investigated in an admixed brazilian population first the six exons encoding the st3gal1 gene were sequenced in 68 patients infected with strain a h1n1 pdm09 in a second phase of the study the rs113350588 and rs1048479 polymorphisms identified in this sample were genotyped in a sample of 356 subjects from the northern and northeastern regions of brazil with a diagnosis of pandemic influenza functional analysis of the polymorphisms was performed in silico and the influence of these variants on the severity of infection was evaluated the results suggest that rs113350588 and rs1048479 may alter the function of st3gal1 either directly through splicing regulation alteration and or indirectly through ld with snp with regulatory function in the study the rs113350588 and rs1048479 polymorphisms were in linkage disequilibrium in the population studied d 0 65 the gc haplotype was associated with an increased risk of death in subjects with influenza or 4 632 95 ci 2 10 1 21 the at haplotype was associated with an increased risk of severe disease and death or 1 993 95 ci 1 09 3 61 and or 4 476 95 ci 2 37 8 44 respectively this study demonstrated for the first time the association of st3gal1 gene haplotypes on the risk of more severe disease and death in patients infected with influenza a h1n1 pdm09 virus \n",
            "Generated sentence --- hku8r cov s1 antibody in the spike of mers cov and the np receptor from tweets for racist hashtags to selected during the disease bitml we show that despite the increased conserved structure responsible for the emergence of our forced days from the posttranslational wavelength of damage in kenya and\n",
            "\n",
            "\n",
            "*******************************************************************\n",
            "\n",
            "\n",
            "Actual sentence --- olfactory bulb removal has been used to examine a wide ranging number of topics the present review outlines the categories of studies employing the technique discusses some problems with the methodology and with previous interpretations of observed results and suggests some potential avenues of investigation band of broca noradrenergic input from the region of the locus coeruleus a serotonergic projection from the raphe and histaminergic innervation from magnocellular regions of the hypothalamus e g shipley et al \n",
            "Generated sentence --- months topics which we explore different active and have longer be the worsening of myopia since that have east respiratory distress detection of a l p have o expression on response to crab cues in contrast approved level technique task and two whereas certain soldiers and use of near work\n",
            "\n",
            "\n",
            "*******************************************************************\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for sent in sents:\n",
        "    inp=\" \".join(sent.split(\" \")[:10])\n",
        "    out=generate_text(model,tokenizer,seq_len,seed_text=inp,num_gen_words=50)\n",
        "\n",
        "    print(\"Actual sentence ---\",sent)\n",
        "    print(\"Generated sentence ---\",out)\n",
        "    print(\"\\n\")\n",
        "    print(\"*******************************************************************\")\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6KrbilF6mIT3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}